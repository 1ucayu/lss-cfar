{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mmWave Radar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation board to get the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only mmwave radar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import serial\n",
    "import time\n",
    "import configparser\n",
    "import json\n",
    "import os\n",
    "\n",
    "def close(self):\n",
    "    \"\"\"End connection between radar and machine\"\"\"\n",
    "    self.cli_port.write('sensorStop\\n'.encode())\n",
    "    self.cli_port.close()\n",
    "    self.data_port.close()\n",
    "\n",
    "def convert_size(size_bytes):\n",
    "    \"\"\"Convert file size to human-readable format\"\"\"\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return f\"{s} {size_name[i]}\"\n",
    "\n",
    "def check_terminate_flag():\n",
    "    \"\"\"Check for termination signal from external file\"\"\"\n",
    "    if os.path.exists(os.path.abspath(os.path.join(os.path.dirname(__file__), '../terminate_flag.txt'))):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Configuration parameters\n",
    "configFileName = 'mmwave_config.cfg'\n",
    "CLIport = {}\n",
    "Dataport = {}\n",
    "byteBuffer = np.zeros(2**20, dtype='uint8')\n",
    "byteBufferLength = 0\n",
    "\n",
    "def serialConfig(configFileName):\n",
    "    \"\"\"Configure the serial ports and send configuration data to the radar\"\"\"\n",
    "    global CLIport\n",
    "    global Dataport\n",
    "    \n",
    "    CLIport = serial.Serial('COM5', 115200)\n",
    "    Dataport = serial.Serial('COM6', 921600)\n",
    "\n",
    "    config = [line.rstrip('\\r\\n') for line in open(configFileName)]\n",
    "    for i in config:\n",
    "        CLIport.write((i + '\\n').encode())\n",
    "        print(i)\n",
    "        time.sleep(0.01)\n",
    "        \n",
    "    return CLIport, Dataport\n",
    "\n",
    "def parseConfigFile(configFileName):\n",
    "    \"\"\"Parse configuration file to extract radar parameters\"\"\"\n",
    "    configParameters = {}\n",
    "    \n",
    "    config = [line.rstrip('\\r\\n') for line in open(configFileName)]\n",
    "    for i in config:\n",
    "        splitWords = i.split(\" \")\n",
    "        numRxAnt = 4\n",
    "        numTxAnt = 3\n",
    "        \n",
    "        if \"profileCfg\" in splitWords[0]:\n",
    "            startFreq = int(float(splitWords[2]))\n",
    "            idleTime = int(splitWords[3])\n",
    "            rampEndTime = float(splitWords[5])\n",
    "            freqSlopeConst = float(splitWords[8])\n",
    "            numAdcSamples = int(splitWords[10])\n",
    "            numAdcSamplesRoundTo2 = 1\n",
    "            \n",
    "            while numAdcSamples > numAdcSamplesRoundTo2:\n",
    "                numAdcSamplesRoundTo2 = numAdcSamplesRoundTo2 * 2\n",
    "                \n",
    "            digOutSampleRate = int(splitWords[11])\n",
    "        \n",
    "        elif \"frameCfg\" in splitWords[0]:\n",
    "            chirpStartIdx = int(splitWords[1])\n",
    "            chirpEndIdx = int(splitWords[2])\n",
    "            numLoops = int(splitWords[3])\n",
    "            numFrames = int(splitWords[4])\n",
    "            framePeriodicity = float(splitWords[5])\n",
    "            \n",
    "    numChirpsPerFrame = (chirpEndIdx - chirpStartIdx + 1) * numLoops\n",
    "    configParameters[\"numDopplerBins\"] = numChirpsPerFrame / numTxAnt\n",
    "    configParameters[\"numRangeBins\"] = numAdcSamplesRoundTo2\n",
    "    configParameters[\"rangeResolutionMeters\"] = (3e8 * digOutSampleRate * 1e3) / (2 * freqSlopeConst * 1e12 * numAdcSamples)\n",
    "    configParameters[\"rangeIdxToMeters\"] = (3e8 * digOutSampleRate * 1e3) / (2 * freqSlopeConst * 1e12 * configParameters[\"numRangeBins\"])\n",
    "    configParameters[\"dopplerResolutionMps\"] = 3e8 / (2 * startFreq * 1e9 * (idleTime + rampEndTime) * 1e-6 * configParameters[\"numDopplerBins\"] * numTxAnt)\n",
    "    configParameters[\"maxRange\"] = (300 * 0.9 * digOutSampleRate) / (2 * freqSlopeConst * 1e3)\n",
    "    configParameters[\"maxVelocity\"] = 3e8 / (4 * startFreq * 1e9 * (idleTime + rampEndTime) * 1e-6 * numTxAnt)\n",
    "    \n",
    "    return configParameters\n",
    "\n",
    "def readAndParseData18xx(Dataport, configParameters):\n",
    "    \"\"\"Read and parse incoming data from the radar\"\"\"\n",
    "    global byteBuffer, byteBufferLength\n",
    "    \n",
    "    OBJ_STRUCT_SIZE_BYTES = 12\n",
    "    BYTE_VEC_ACC_MAX_SIZE = 2**15\n",
    "    MMWDEMO_UART_MSG_DETECTED_POINTS = 1\n",
    "    MMWDEMO_UART_MSG_RANGE_PROFILE = 2\n",
    "    maxBufferSize = 2**15\n",
    "    tlvHeaderLengthInBytes = 8\n",
    "    pointLengthInBytes = 16\n",
    "    magicWord = [2, 1, 4, 3, 6, 5, 8, 7]\n",
    "    \n",
    "    magicOK = 0\n",
    "    dataOK = 0\n",
    "    frameNumber = 0\n",
    "    detObj = {}\n",
    "    \n",
    "    readBuffer = Dataport.read(Dataport.in_waiting)\n",
    "    byteVec = np.frombuffer(readBuffer, dtype='uint8')\n",
    "    byteCount = len(byteVec)\n",
    "    \n",
    "    if (byteBufferLength + byteCount) < maxBufferSize:\n",
    "        byteBuffer[byteBufferLength:byteBufferLength + byteCount] = byteVec[:byteCount]\n",
    "        byteBufferLength = byteBufferLength + byteCount\n",
    "        \n",
    "    if byteBufferLength > 16:\n",
    "        possibleLocs = np.where(byteBuffer == magicWord[0])[0]\n",
    "        startIdx = []\n",
    "        for loc in possibleLocs:\n",
    "            check = byteBuffer[loc:loc+8]\n",
    "            if np.all(check == magicWord):\n",
    "                startIdx.append(loc)\n",
    "               \n",
    "        if startIdx:\n",
    "            if startIdx[0] > 0 and startIdx[0] < byteBufferLength:\n",
    "                byteBuffer[:byteBufferLength-startIdx[0]] = byteBuffer[startIdx[0]:byteBufferLength]\n",
    "                byteBuffer[byteBufferLength-startIdx[0]:] = np.zeros(len(byteBuffer[byteBufferLength-startIdx[0]:]), dtype='uint8')\n",
    "                byteBufferLength = byteBufferLength - startIdx[0]\n",
    "                \n",
    "            if byteBufferLength < 0:\n",
    "                byteBufferLength = 0\n",
    "                \n",
    "            word = [1, 2**8, 2**16, 2**24]\n",
    "            totalPacketLen = np.matmul(byteBuffer[12:12+4], word)\n",
    "            \n",
    "            if (byteBufferLength >= totalPacketLen) and (byteBufferLength != 0):\n",
    "                magicOK = 1\n",
    "    \n",
    "    if magicOK:\n",
    "        word = [1, 2**8, 2**16, 2**24]\n",
    "        idX = 0\n",
    "        \n",
    "        magicNumber = byteBuffer[idX:idX+8]\n",
    "        idX += 8\n",
    "        version = format(np.matmul(byteBuffer[idX:idX+4], word), 'x')\n",
    "        idX += 4\n",
    "        totalPacketLen = np.matmul(byteBuffer[idX:idX+4], word)\n",
    "        idX += 4\n",
    "        platform = format(np.matmul(byteBuffer[idX:idX+4], word), 'x')\n",
    "        idX += 4\n",
    "        frameNumber = np.matmul(byteBuffer[idX:idX+4], word)\n",
    "        idX += 4\n",
    "        timeCpuCycles = np.matmul(byteBuffer[idX:idX+4], word)\n",
    "        idX += 4\n",
    "        numDetectedObj = np.matmul(byteBuffer[idX:idX+4], word)\n",
    "        idX += 4\n",
    "        numTLVs = np.matmul(byteBuffer[idX:idX+4], word)\n",
    "        idX += 4\n",
    "        subFrameNumber = np.matmul(byteBuffer[idX:idX+4], word)\n",
    "        idX += 4\n",
    "\n",
    "        for tlvIdx in range(numTLVs):\n",
    "            word = [1, 2**8, 2**16, 2**24]\n",
    "            tlv_type = np.matmul(byteBuffer[idX:idX+4], word)\n",
    "            idX += 4\n",
    "            tlv_length = np.matmul(byteBuffer[idX:idX+4], word)\n",
    "            idX += 4\n",
    "\n",
    "            if tlv_type == MMWDEMO_UART_MSG_DETECTED_POINTS:\n",
    "                x = np.zeros(numDetectedObj, dtype=np.float32)\n",
    "                y = np.zeros(numDetectedObj, dtype=np.float32)\n",
    "                z = np.zeros(numDetectedObj, dtype=np.float32)\n",
    "                velocity = np.zeros(numDetectedObj, dtype=np.float32)\n",
    "                \n",
    "                for objectNum in range(numDetectedObj):\n",
    "                    x[objectNum] = byteBuffer[idX:idX + 4].view(dtype=np.float32)\n",
    "                    idX += 4\n",
    "                    y[objectNum] = byteBuffer[idX:idX + 4].view(dtype=np.float32)\n",
    "                    idX += 4\n",
    "                    z[objectNum] = byteBuffer[idX:idX + 4].view(dtype=np.float32)\n",
    "                    idX += 4\n",
    "                    velocity[objectNum] = byteBuffer[idX:idX + 4].view(dtype=np.float32)\n",
    "                    idX += 4\n",
    "                \n",
    "                detObj = {\"numObj\": numDetectedObj, \"x\": x, \"y\": y, \"z\": z, \"velocity\": velocity}\n",
    "                dataOK = 1\n",
    "                \n",
    "        if idX > 0 and byteBufferLength > idX:\n",
    "            shiftSize = totalPacketLen\n",
    "            byteBuffer[:byteBufferLength - shiftSize] = byteBuffer[shiftSize:byteBufferLength]\n",
    "            byteBuffer[byteBufferLength - shiftSize:] = np.zeros(len(byteBuffer[byteBufferLength - shiftSize:]), dtype='uint8')\n",
    "            byteBufferLength = byteBufferLength - shiftSize\n",
    "            \n",
    "            if byteBufferLength < 0:\n",
    "                byteBufferLength = 0         \n",
    "\n",
    "    return dataOK, frameNumber, detObj\n",
    "\n",
    "def update():\n",
    "    \"\"\"Update the data and display in the plot\"\"\"\n",
    "    dataOk = 0\n",
    "    global detObj\n",
    "    global scatter_plot_collection \n",
    "    x = []\n",
    "    y = []\n",
    "      \n",
    "    dataOk, frameNumber, detObj = readAndParseData18xx(Dataport, configParameters)\n",
    "    \n",
    "    if dataOk and len(detObj[\"x\"]) > 0:\n",
    "        x = -detObj[\"x\"]\n",
    "        y = detObj[\"y\"]\n",
    "        \n",
    "        if scatter_plot_collection:\n",
    "            scatter_plot_collection.remove()\n",
    "\n",
    "        scatter_plot_collection = ax.scatter(x, y, detObj[\"z\"], c='r', marker='o')\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)\n",
    "        # QtWidgets.QApplication.processEvents()\n",
    "    \n",
    "    return dataOk\n",
    "\n",
    "# Main execution\n",
    "CLIport, Dataport = serialConfig(configFileName)\n",
    "configParameters = parseConfigFile(configFileName)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('X position (m)')\n",
    "ax.set_ylabel('Y position (m)')\n",
    "ax.set_zlabel('Z position (m)')\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(0, 3)\n",
    "ax.set_zlim(-5, 5)\n",
    "scatter_plot_collection = ax.scatter([], [], [], c='r', marker='o')\n",
    "\n",
    "detObj = {}  \n",
    "frameData = {}    \n",
    "currentIndex = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        dataOk = update()\n",
    "        if check_terminate_flag():\n",
    "            CLIport.write(('sensorStop\\n').encode())\n",
    "            CLIport.close()\n",
    "            Dataport.close()\n",
    "            break\n",
    "        time.sleep(0.001)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        CLIport.write(('sensorStop\\n').encode())\n",
    "        CLIport.close()\n",
    "        Dataport.close()\n",
    "        plt.close()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "config.cfg file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% ***************************************************************\n",
    "% Created for SDK ver:03.06\n",
    "% Created using Visualizer ver:3.6.0.0\n",
    "% Frequency:77\n",
    "% Platform:xWR18xx\n",
    "% Scene Classifier:best_range_res\n",
    "% Azimuth Resolution(deg):15 + Elevation\n",
    "% Range Resolution(m):0.044\n",
    "% Maximum unambiguous Range(m):9.02\n",
    "% Maximum Radial Velocity(m/s):1\n",
    "% Radial velocity resolution(m/s):0.13\n",
    "% Frame Duration(msec):10\n",
    "% RF calibration data:None\n",
    "% Range Detection Threshold (dB):15\n",
    "% Doppler Detection Threshold (dB):15\n",
    "% Range Peak Grouping:enabled\n",
    "% Doppler Peak Grouping:enabled\n",
    "% Static clutter removal:disabled\n",
    "% Angle of Arrival FoV: Full FoV\n",
    "% Range FoV: Full FoV\n",
    "% Doppler FoV: Full FoV\n",
    "% ***************************************************************\n",
    "sensorStop\n",
    "flushCfg\n",
    "dfeDataOutputMode 1\n",
    "channelCfg 15 7 0\n",
    "adcCfg 2 1\n",
    "adcbufCfg -1 0 1 1 1\n",
    "profileCfg 0 77 267 7 57.14 0 0 70 1 256 5209 0 0 30\n",
    "chirpCfg 0 0 0 0 0 0 0 1\n",
    "chirpCfg 1 1 0 0 0 0 0 4\n",
    "chirpCfg 2 2 0 0 0 0 0 2\n",
    "frameCfg 0 2 16 0 100 1 0\n",
    "lowPower 0 0\n",
    "guiMonitor -1 1 1 0 0 0 1\n",
    "cfarCfg -1 0 2 8 4 3 0 15 1\n",
    "cfarCfg -1 1 0 4 2 3 1 15 1\n",
    "multiObjBeamForming -1 1 0.5\n",
    "clutterRemoval -1 0\n",
    "calibDcRangeSig -1 0 -5 8 256\n",
    "extendedMaxVelocity -1 0\n",
    "lvdsStreamCfg -1 0 0 0\n",
    "compRangeBiasAndRxChanPhase 0.0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
    "measureRangeBiasAndRxChanPhase 0 1.5 0.2\n",
    "CQRxSatMonitor 0 3 5 121 0\n",
    "CQSigImgMonitor 0 127 4\n",
    "analogMonitor 0 0\n",
    "aoaFovCfg -1 -90 90 -90 90\n",
    "cfarFovCfg -1 0 0 8.92\n",
    "cfarFovCfg -1 1 -1 1.00\n",
    "calibData 0 0 0\n",
    "sensorStart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Camera\n",
    "D435, datasheet: https://store.intelrealsense.com/buy-intel-realsense-depth-camera-d435.html#\n",
    "\n",
    "\n",
    "D355, dataseheet: https://store.intelrealsense.com/buy-intel-realsense-depth-camera-d455.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only pointcloud 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "class AppState:\n",
    "    def __init__(self):\n",
    "        self.paused = False\n",
    "        self.decimate = 0\n",
    "\n",
    "state = AppState()\n",
    "\n",
    "# Configure streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "# Start streaming\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "# Getting the depth sensor's depth scale (see rs-align example for explanation)\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "print(\"Depth Scale is: \" , depth_scale)\n",
    "\n",
    "# Create an align object\n",
    "# rs.align allows us to perform alignment of depth frames to others frames\n",
    "# The \"align_to\" is the stream type to which we plan to align depth frames.\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# Processing blocks\n",
    "pc = rs.pointcloud()\n",
    "decimate = rs.decimation_filter()\n",
    "decimate.set_option(rs.option.filter_magnitude, 2 ** state.decimate)\n",
    "\n",
    "def get_point_cloud(aligned_depth_frame):\n",
    "    depth_frame = decimate.process(aligned_depth_frame)\n",
    "    points = pc.calculate(depth_frame)\n",
    "    verts = np.asarray(points.get_vertices()).view(np.float32).reshape(-1, 3)\n",
    "    return verts\n",
    "\n",
    "try:\n",
    "    plt.ion()\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_title(\"3D Point Cloud\")\n",
    "\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        verts = get_point_cloud(aligned_depth_frame)\n",
    "\n",
    "        # Clear the 3D plot and plot the new point cloud\n",
    "        ax.cla()\n",
    "        ax.set_title(\"3D Point Cloud\")\n",
    "        ax.scatter(verts[:, 0], verts[:, 1], verts[:, 2], c=verts[:, 2], cmap='jet', s=1)\n",
    "\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    plt.ioff()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pointcloud3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import cv2\n",
    "\n",
    "class AppState:\n",
    "    def __init__(self):\n",
    "        self.paused = False\n",
    "        self.decimate = 0\n",
    "\n",
    "state = AppState()\n",
    "\n",
    "# Configure streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "# Start streaming\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "# Getting the depth sensor's depth scale (see rs-align example for explanation)\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "print(\"Depth Scale is: \" , depth_scale)\n",
    "\n",
    "# Create an align object\n",
    "# rs.align allows us to perform alignment of depth frames to others frames\n",
    "# The \"align_to\" is the stream type to which we plan to align depth frames.\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# Processing blocks\n",
    "pc = rs.pointcloud()\n",
    "decimate = rs.decimation_filter()\n",
    "decimate.set_option(rs.option.filter_magnitude, 2 ** state.decimate)\n",
    "\n",
    "def get_point_cloud(aligned_depth_frame):\n",
    "    depth_frame = decimate.process(aligned_depth_frame)\n",
    "    points = pc.calculate(depth_frame)\n",
    "    verts = np.asarray(points.get_vertices()).view(np.float32).reshape(-1, 3)\n",
    "    return verts\n",
    "\n",
    "try:\n",
    "    plt.ion()\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "    ax1 = fig.add_subplot(131, projection='3d')\n",
    "    ax2 = fig.add_subplot(132)\n",
    "    ax3 = fig.add_subplot(133)\n",
    "\n",
    "    ax1.set_title(\"3D Point Cloud\")\n",
    "    ax2.set_title(\"RGB Image\")\n",
    "    ax3.set_title(\"Depth Colormap\")\n",
    "\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # Render images:\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Update RGB image\n",
    "        ax2.imshow(cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB))\n",
    "        ax2.axis('off')\n",
    "\n",
    "        # Update Depth colormap\n",
    "        ax3.imshow(cv2.cvtColor(depth_colormap, cv2.COLOR_BGR2RGB))\n",
    "        ax3.axis('off')\n",
    "\n",
    "        verts = get_point_cloud(aligned_depth_frame)\n",
    "\n",
    "        # Clear the 3D plot and plot the new point cloud\n",
    "        ax1.cla()\n",
    "        ax1.set_title(\"3D Point Cloud\")\n",
    "        ax1.scatter(verts[:, 0], verts[:, 1], verts[:, 2], c=verts[:, 2], cmap='jet', s=1)\n",
    "\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    plt.ioff()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "class AppState:\n",
    "    def __init__(self):\n",
    "        self.paused = False\n",
    "        self.decimate = 0\n",
    "\n",
    "state = AppState()\n",
    "\n",
    "# Configure streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "\n",
    "config.enable_stream(rs.stream.depth, rs.format.z16, 30)\n",
    "pipeline.start(config)\n",
    "profile = pipeline.get_active_profile()\n",
    "\n",
    "depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "depth_intrinsics = depth_profile.get_intrinsics()\n",
    "w, h = depth_intrinsics.width, depth_intrinsics.height\n",
    "\n",
    "# Processing blocks\n",
    "pc = rs.pointcloud()\n",
    "decimate = rs.decimation_filter()\n",
    "decimate.set_option(rs.option.filter_magnitude, 2 ** state.decimate)\n",
    "\n",
    "def get_point_cloud():\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    depth_frame = frames.get_depth_frame()\n",
    "\n",
    "    depth_frame = decimate.process(depth_frame)\n",
    "\n",
    "    # Calculate the point cloud\n",
    "    points = pc.calculate(depth_frame)\n",
    "    verts = np.asarray(points.get_vertices()).view(np.float32).reshape(-1, 3)\n",
    "\n",
    "    return verts\n",
    "\n",
    "# Start streaming\n",
    "try:\n",
    "    plt.ion()\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Create subplots\n",
    "    ax2d = fig.add_subplot(121)\n",
    "    ax3d = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "    # Set fixed axis limits for the 2D plot\n",
    "    ax2d.set_xlim(-1, 1)  # Adjust these values as necessary\n",
    "    ax2d.set_ylim(1, -1)  # Reverse the Y-axis\n",
    "\n",
    "    scatter2d = ax2d.scatter([], [], s=1, c='black')\n",
    "\n",
    "    while True:\n",
    "        verts = get_point_cloud()\n",
    "\n",
    "        # Extract X, Y, and Z coordinates\n",
    "        x = verts[:, 0]\n",
    "        y = verts[:, 1]\n",
    "        z = verts[:, 2]\n",
    "\n",
    "        # Update 2D scatter plot\n",
    "        scatter2d.set_offsets(np.c_[x, y])\n",
    "        ax2d.set_title(\"Point Cloud in X-Y Plane\")\n",
    "        ax2d.set_xlabel(\"X\")\n",
    "        ax2d.set_ylabel(\"Y\")\n",
    "        ax2d.axis('equal')\n",
    "\n",
    "        # Update 3D scatter plot\n",
    "        ax3d.cla()\n",
    "        ax3d.scatter(x, y, z, s=1, c='black')\n",
    "        ax3d.set_title(\"3D Point Cloud\")\n",
    "        ax3d.set_xlabel(\"X\")\n",
    "        ax3d.set_ylabel(\"Y\")\n",
    "        ax3d.set_zlabel(\"Z\")\n",
    "\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pointcloud 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class AppState:\n",
    "    def __init__(self):\n",
    "        self.paused = False\n",
    "        self.decimate = 0\n",
    "\n",
    "state = AppState()\n",
    "\n",
    "# Configure streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "\n",
    "config.enable_stream(rs.stream.depth, rs.format.z16, 30)\n",
    "pipeline.start(config)\n",
    "profile = pipeline.get_active_profile()\n",
    "\n",
    "depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "depth_intrinsics = depth_profile.get_intrinsics()\n",
    "w, h = depth_intrinsics.width, depth_intrinsics.height\n",
    "\n",
    "# Processing blocks\n",
    "pc = rs.pointcloud()\n",
    "decimate = rs.decimation_filter()\n",
    "decimate.set_option(rs.option.filter_magnitude, 2 ** state.decimate)\n",
    "\n",
    "def get_point_cloud():\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    depth_frame = frames.get_depth_frame()\n",
    "\n",
    "    depth_frame = decimate.process(depth_frame)\n",
    "\n",
    "    # Calculate the point cloud\n",
    "    points = pc.calculate(depth_frame)\n",
    "    verts = np.asarray(points.get_vertices()).view(np.float32).reshape(-1, 3)\n",
    "\n",
    "    return verts\n",
    "\n",
    "# Start streaming\n",
    "try:\n",
    "    plt.ion()\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    # Set fixed axis limits based on the expected range of the point cloud data\n",
    "    ax.set_xlim(-1, 1)  # Adjust these values as necessary\n",
    "    ax.set_ylim(1, -1)  # Reverse the Y-axis\n",
    "\n",
    "    scatter = ax.scatter([], [], s=1, c='black')\n",
    "\n",
    "    while True:\n",
    "        verts = get_point_cloud()\n",
    "\n",
    "        # Extract X and Y coordinates\n",
    "        x = verts[:, 0]\n",
    "        y = verts[:, 1]\n",
    "\n",
    "        scatter.set_offsets(np.c_[x, y])\n",
    "        ax.set_title(\"Point Cloud in X-Y Plane\")\n",
    "        ax.set_xlabel(\"X\")\n",
    "        ax.set_ylabel(\"Y\")\n",
    "        ax.axis('equal')\n",
    "\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pintcloud 2d+3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aligned sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## License: Apache 2.0. See LICENSE file in root directory.\n",
    "## Copyright(c) 2017 Intel Corporation. All Rights Reserved.\n",
    "\n",
    "#####################################################\n",
    "##              Align Depth to Color               ##\n",
    "#####################################################\n",
    "\n",
    "# First import the library\n",
    "import pyrealsense2 as rs\n",
    "# Import Numpy for easy array manipulation\n",
    "import numpy as np\n",
    "# Import OpenCV for easy image rendering\n",
    "import cv2\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Create a config and configure the pipeline to stream\n",
    "#  different resolutions of color and depth streams\n",
    "config = rs.config()\n",
    "\n",
    "# Get device product line for setting a supporting resolution\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "# Start streaming\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "# Getting the depth sensor's depth scale (see rs-align example for explanation)\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "print(\"Depth Scale is: \" , depth_scale)\n",
    "\n",
    "# We will be removing the background of objects more than\n",
    "#  clipping_distance_in_meters meters away\n",
    "clipping_distance_in_meters = 1 #1 meter\n",
    "clipping_distance = clipping_distance_in_meters / depth_scale\n",
    "\n",
    "# Create an align object\n",
    "# rs.align allows us to perform alignment of depth frames to others frames\n",
    "# The \"align_to\" is the stream type to which we plan to align depth frames.\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# Streaming loop\n",
    "try:\n",
    "    while True:\n",
    "        # Get frameset of color and depth\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        # frames.get_depth_frame() is a 640x360 depth image\n",
    "\n",
    "        # Align the depth frame to color frame\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        # Get aligned frames\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame() # aligned_depth_frame is a 640x480 depth image\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "        # Validate that both frames are valid\n",
    "        if not aligned_depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # Remove background - Set pixels further than clipping_distance to grey\n",
    "        grey_color = 153\n",
    "        depth_image_3d = np.dstack((depth_image,depth_image,depth_image)) #depth image is 1 channel, color is 3 channels\n",
    "        bg_removed = np.where((depth_image_3d > clipping_distance) | (depth_image_3d <= 0), grey_color, color_image)\n",
    "\n",
    "        # Render images:\n",
    "        #   depth align to color on left\n",
    "        #   depth on right\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "        images = np.hstack((bg_removed, depth_colormap))\n",
    "\n",
    "        cv2.namedWindow('Align Example', cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow('Align Example', images)\n",
    "        key = cv2.waitKey(1)\n",
    "        # Press esc or 'q' to close the image window\n",
    "        if key & 0xFF == ord('q') or key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "finally:\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pointcloud sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## License: Apache 2.0. See LICENSE file in root directory.\n",
    "## Copyright(c) 2017 Intel Corporation. All Rights Reserved.\n",
    "\n",
    "#####################################################\n",
    "##                  Export to PLY                  ##\n",
    "#####################################################\n",
    "\n",
    "# First import the library\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "\n",
    "# Declare pointcloud object, for calculating pointclouds and texture mappings\n",
    "pc = rs.pointcloud()\n",
    "# We want the points object to be persistent so we can display the last cloud when a frame drops\n",
    "points = rs.points()\n",
    "\n",
    "# Declare RealSense pipeline, encapsulating the actual device and sensors\n",
    "pipe = rs.pipeline()\n",
    "config = rs.config()\n",
    "# Enable depth stream\n",
    "config.enable_stream(rs.stream.depth)\n",
    "\n",
    "# Start streaming with chosen configuration\n",
    "pipe.start(config)\n",
    "\n",
    "# We'll use the colorizer to generate texture for our PLY\n",
    "# (alternatively, texture can be obtained from color or infrared stream)\n",
    "colorizer = rs.colorizer()\n",
    "\n",
    "try:\n",
    "    # Wait for the next set of frames from the camera\n",
    "    frames = pipe.wait_for_frames()\n",
    "    colorized = colorizer.process(frames)\n",
    "\n",
    "    # Create save_to_ply object\n",
    "    ply = rs.save_to_ply(\"1.ply\")\n",
    "\n",
    "    # Set options to the desired values\n",
    "    # In this example we'll generate a textual PLY with normals (mesh is already created by default)\n",
    "    ply.set_option(rs.save_to_ply.option_ply_binary, False)\n",
    "    ply.set_option(rs.save_to_ply.option_ply_normals, True)\n",
    "\n",
    "    print(\"Saving to 1.ply...\")\n",
    "    # Apply the processing block to the frameset which contains the depth frame and the texture\n",
    "    ply.process(colorized)\n",
    "    print(\"Done\")\n",
    "finally:\n",
    "    pipe.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmwave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
